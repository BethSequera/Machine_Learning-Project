{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics Avengers: Water Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (907029512.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    San_Francisco_path = Path(..\"Data/Analytics_Avengers-SF_CA_Sea_Levels.csv\")\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# File to Load\n",
    "San_Francisco_path = Path(..\"Data/Analytics_Avengers-SF_CA_Sea_Levels.csv\")\n",
    "San_Diego_path = Path(..\"Data/Analytics_Avengers-San_Diego_CA_Sea_Levels.csv\")\n",
    "Key_West_path = Path(..\"Data/Analytics_Avengers-Key_West_FL_Sea_Level.csv\")\n",
    "Honolulu_path = Path(..\"Data/Analytics_Avengers-Honolulu_Hi_Sea_Levels.csv\")\n",
    "Charleston_path = Path(..\"Data/Analytics_Avengers-Charleston_SC_Sea_Level.csv\")\n",
    "Boston_path = Path(..\"Data/Analytics_Avengers-Boston_MA_Sea_Levels.csv\")\n",
    "Seattle_path = Path(..\"Data/Analytics_Avengers-Seattle_WA_Sea_Level.csv\")\n",
    "\n",
    "# Read Data Files and store them into Pandas DataFrames\n",
    "San_Francisco = pd.read_csv(San_Francisco_path)\n",
    "San_Diego = pd.read_csv(San_Diego_path)\n",
    "Key_West = pd.read_csv(Key_West_path)\n",
    "Honolulu = pd.read_csv(Honolulu_path)\n",
    "Charleston = pd.read_csv(Charleston_path)\n",
    "Boston = pd.read_csv(Boston_path)\n",
    "Seattle = pd.read_csv(Seattle_path)\n",
    "\n",
    "# Display the first few rows of the San Francisco DataFrame\n",
    "San_Francisco.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "San_Diego.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Key_West.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Honolulu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Charleston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seattle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of file paths\n",
    "file_paths = [\n",
    "    \"Data/Analytics_Avengers-SF_CA_Sea_Levels.csv\",\n",
    "    \"Data/Analytics_Avengers-San_Diego_CA_Sea_Levels.csv\",\n",
    "    \"Data/Analytics_Avengers-Key_West_FL_Sea_Level.csv\",\n",
    "    \"Data/Analytics_Avengers-Honolulu_Hi_Sea_Levels.csv\",\n",
    "    \"Data/Analytics_Avengers-Charleston_SC_Sea_Level.csv\",\n",
    "    \"Data/Analytics_Avengers-Boston_MA_Sea_Levels.csv\",\n",
    "    \"Data/Analytics_Avengers-Seattle_WA_Sea_Level.csv\"\n",
    "]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the file paths and read each CSV file into a DataFrame\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames vertically into one\n",
    "merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Time (GMT)', 'Highest', 'MHHW (ft)', 'MTL (ft)', 'MLLW (ft)', 'Lowest (ft)', 'Inf']\n",
    "merged_data_new = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm the columns have been dropped\n",
    "merged_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = merged_data_new.isnull().sum()\n",
    "\n",
    "# Print missing values before filling\n",
    "print(\"Missing Values Before Filling:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "output_file_path = \"reduced_data.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "merged_data_new.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the database connection URL. For SQLite, use a file path.\n",
    "database_url = \"sqlite:///sea_level_data.db\" \n",
    "\n",
    "# Create a SQLAlchemy engine to connect to the database\n",
    "engine = create_engine(database_url)\n",
    "\n",
    "# Write the DataFrame to the database\n",
    "reduced_data.to_sql(\"sea_level_data\", con=engine, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "merged_data_new['Date'] = pd.to_datetime(merged_data_new['Date'])\n",
    "\n",
    "# Extract the year from the 'Date' column and add it as a new column\n",
    "merged_data_new['Year'] = merged_data_new['Date'].dt.year\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm the columns have been dropped\n",
    "merged_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the annual averages\n",
    "annual_averages = merged_data_new.groupby('Year')['MSL (ft)'].mean()\n",
    "\n",
    "# Display the annual averages\n",
    "print(\"Annual Averages:\")\n",
    "print(annual_averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = merged_data_new[['Year']]\n",
    "y = merged_data_new['MSL (ft)']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for different time periods\n",
    "years_to_predict = [10, 25, 50, 75, 100]\n",
    "\n",
    "# Create a new DataFrame to hold the future years for prediction\n",
    "future_years_df = pd.DataFrame({'Year': [year + merged_data_new['Year'].max() for year in years_to_predict]})\n",
    "\n",
    "# Predict for future years\n",
    "future_predictions = model.predict(future_years_df)\n",
    "\n",
    "# Display the predictions\n",
    "for year, prediction in zip(years_to_predict, future_predictions):\n",
    "    print(f\"Predicted Mean Coastal Sea Level in {year} years: {prediction:.2f} ft\")\n",
    "\n",
    "# Evaluate the model (for example, using Mean Absolute Error) on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error on Test Data: {mae:.2f} ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of unique cities in your dataset\n",
    "unique_cities = merged_data_new['City'].unique()\n",
    "\n",
    "# Loop through each city\n",
    "for city in unique_cities:\n",
    "    # Filter the data for the current city\n",
    "    city_data = merged_data_new[merged_data_new['City'] == city]\n",
    "\n",
    "    # Extract the year and MSL (ft) for the current city\n",
    "    X_city = city_data[['Year']]\n",
    "    y_city = city_data['MSL (ft)']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train_city, X_test_city, y_train_city, y_test_city = train_test_split(X_city, y_city, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the Linear Regression model for the current city\n",
    "    model_city = LinearRegression()\n",
    "    model_city.fit(X_train_city, y_train_city)\n",
    "\n",
    "    # Make predictions for original and future years\n",
    "    years_to_predict_city = list(city_data['Year']) + [year + city_data['Year'].max() for year in years_to_predict]\n",
    "    predictions_city = model_city.predict([[year] for year in years_to_predict_city])\n",
    "\n",
    "    # Create a plot to visualize the original data and predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_city, y_city, label=\"Original Data\", marker='o', color='blue')\n",
    "    plt.plot(years_to_predict_city, predictions_city, label=\"Predicted Data\", linestyle='--', color='red')\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"MSL (ft)\")\n",
    "    plt.title(f\"{city} Sea Level Prediction\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for San Francisco\n",
    "san_francisco_data = merged_data_new[merged_data_new['City'] == 'San Francisco']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "sf_years = san_francisco_data['Year']\n",
    "sf_msl = san_francisco_data['MSL (ft)']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sf_years, sf_msl, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in San Francisco Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for Boston\n",
    "boston_data = merged_data_new[merged_data_new['City'] == 'Boston']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "boston_years = boston_data['Year']\n",
    "boston_msl = boston_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in Boston Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for Charleston\n",
    "charleston_data = reduced_data[reduced_data['City'] == 'Charleston']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "years = charleston_data['Year']\n",
    "mean_highest = charleston_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in Charleston Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for Honolulu\n",
    "honolulu_data = reduced_data[reduced_data['City'] == 'Honolulu']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "years = honolulu_data['Year']\n",
    "mean_highest = honolulu_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in Honolulu Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for Honolulu\n",
    "key_west_data = reduced_data[reduced_data['City'] == 'Key West']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "years = key_west_data['Year']\n",
    "mean_highest = key_west_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in Key West Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data for San Diego\n",
    "san_diego_data = reduced_data[reduced_data['City'] == 'San Diego']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "years = san_diego_data['Year']\n",
    "mean_highest = san_diego_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in San Diego Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for San Diego\n",
    "san_diego_data = reduced_data[reduced_data['City'] == 'San Diego']\n",
    "\n",
    "# Extract the year and mean highest columns\n",
    "years = san_diego_data['Year']\n",
    "mean_highest = san_diego_data['Mean Highest']\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, mean_highest, marker='o', linestyle='-')\n",
    "plt.title('Mean Highest Coastal Sea Level in San Diego Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Highest Sea Level (ft)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
